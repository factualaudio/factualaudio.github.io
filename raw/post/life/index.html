<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <title>From bytes to your eardrum &middot; Factual Audio</title>
        <meta name="description" content="In the previous post, I described how an audio signal is represented. Now, let’s discuss the various physical forms that audio signals take as they travel through each stage of an audio playback system.
For the sake of this discussion, I am going to assume the most common and straightforward use case: playing a digital stream over loudspeakers (or headphones). By “digital stream” I mean any audio signal that is processed by a computer or computer-like system; that can be anything including a MP3 file, online video, online music streaming, the soundtrack of a Blu-ray disc, etc.">
        <meta name="HandheldFriendly" content="True">
        <meta name="MobileOptimized" content="320">
        <meta name="generator" content="Hugo 0.26" />
        <meta name="robots" content="index,follow">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta name="theme-color" content="#f03838">
        
        <link rel="stylesheet" href="https://factualaudio.com/dist/styles.css" data-concatenate-into="https://factualaudio.com/combined.css">
        
        <noscript class="defer">
            <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css">
        </noscript>
	<script defer src="https://cdnjs.cloudflare.com/ajax/libs/webfont/1.6.28/webfontloader.js" data-concatenate-into="https://factualaudio.com/combined.js"></script>
	<script defer src="https://factualaudio.com/js/fonts.js" data-concatenate-into="https://factualaudio.com/combined.js"></script>
        <script defer src="https://factualaudio.com/js/defer.js" data-concatenate-into="https://factualaudio.com/combined.js"></script>
        
        <link rel="icon" href="https://factualaudio.com/icon.png" type="image/png">
<link rel="stylesheet" href="https://cdn.rawgit.com/lemonmade/bigfoot/2.1.4/dist/bigfoot-default.css" data-concatenate-into="https://factualaudio.com/combined.css">
<link rel="stylesheet" href="https://factualaudio.com/styles.css" data-concatenate-into="https://factualaudio.com/combined.css">

<noscript>
	<style>
		.inlineFootnoteDecoration {
			display: inline;
		}
		.inlineFootnoteUnprocessed {
			display: inline;
			font-size: inherit;
			background-color: transparent;
		}
	</style>
</noscript>
<script defer src="https://code.jquery.com/jquery-3.2.1.slim.js" data-concatenate-into="https://factualaudio.com/combined.js"></script>
<script defer src="https://cdn.rawgit.com/lemonmade/bigfoot/2.1.4/dist/bigfoot.js" data-concatenate-into="https://factualaudio.com/combined.js"></script>
<script defer src="https://factualaudio.com/inline_footnotes.js" data-concatenate-into="https://factualaudio.com/combined.js"></script>
<script defer src="https://factualaudio.com/bigfoot.js" data-concatenate-into="https://factualaudio.com/combined.js"></script>
<script defer src="https://factualaudio.com/replacewithsvg.js" data-concatenate-into="https://factualaudio.com/combined.js"></script>
<script defer src="https://factualaudio.com/disqus.js" data-concatenate-into="https://factualaudio.com/combined.js"></script>
<script defer src="https://factualaudio.com/google_analytics.js" data-concatenate-into="https://factualaudio.com/combined.js"></script>

    </head>
    <body>
        

        <div id="wrapper">
            <header class="site-header">
                <div class="container">
                    <div class="site-title-wrapper">
                        
                            <h1 class="site-title">
                                <a title="Factual Audio" href="https://factualaudio.com/">Factual Audio</a>
                            </h1>
                        
                        <a class="button-square" href="https://factualaudio.com/index.xml"><i class="fa fa-rss"></i></a>
                        
                            <a class="button-square button-social hint--top" data-hint="Facebook" title="Facebook" href="https://www.facebook.com/FactualAudio/">
                                <i class="fa fa-facebook"></i>
                            </a>
                        
                        
                            <a class="button-square button-social hint--top" data-hint="Twitter" title="Twitter" href="https://twitter.com/FactualAudio">
                                <i class="fa fa-twitter"></i>
                            </a>
                        
                        
                        
                        
                        
                        
                        
                    </div>

                    <ul class="site-nav">
                        
                    </ul>
                </div>
            </header>

            <div id="container">


<div class="container">
    <article class="post-container" itemscope="" itemtype="http://schema.org/BlogPosting">
        <header class="post-header">
    <h1 class="post-title" itemprop="name headline">From bytes to your eardrum</h1>
    
    <p class="post-date">
        <span>Published <time datetime="2017-11-21" itemprop="datePublished">Tue, Nov 21, 2017</time></span>
        <span>by</span>
        <span itemscope="" itemprop="author" itemtype="https://schema.org/Person">
            <span itemprop="name">
                <a href="https://factualaudio.com/page/about/" itemprop="url" rel="author">Etienne Dechamps</a>
            </span>
        </span>
    </p>
</header>

        <div class="post-content clearfix" itemprop="articleBody">
    

    

<p>In the <a href="https://factualaudio.com/post/anatomy/">previous post</a>, I described how an audio signal is represented. Now, let’s discuss the various physical forms that audio signals take as they travel through each stage of an audio playback system.</p>

<p>For the sake of this discussion, I am going to assume the most common and straightforward use case: playing a <em>digital stream</em> over loudspeakers (or headphones). By “digital stream” I mean any audio signal that is processed by a computer or computer-like system; that can be anything including a MP3 file, online video, online music streaming, the soundtrack of a Blu-ray disc, etc. This does not include analogue media such as vinyl discs or cassette tapes.</p>

<p>Before this digital content can reach your eardrums, it has to go through a series of steps. Between these steps, the audio signal is materialized in different ways depending on which part of the audio “pipeline” we are looking at. In this post I refer to these concrete representations as <em>realms</em> <strong class="inlineFootnoteDecoration"> [note] </strong><span class="inlineFootnote-note inlineFootnoteUnprocessed">“realm” is not a widely used term — the term “domain” is normally used. However, I felt that this could create confusion with <em>time domain</em> and <em>frequency domain</em>, which are completely unrelated concepts.</span><strong class="inlineFootnoteDecoration"> [end note] </strong>. I am going to start at the source and then make my way through to the listener.</p>

<p>To keep things clear and simple, the example signal I’ll use throughout this post is a monophonic (one channel) 1 kHz sine wave. For all intents of purposes, each additional channel can be assumed to act like a completely separate audio signal that takes a similar path through the system.</p>

<span class="figure" data-intrinsic-placeholder="unprocessed">
	<img src="https://factualaudio.com/diagrams/realms.png" alt="Audio pipeline diagram" data-svg-alternative="https://factualaudio.com/diagrams/realms.svg">
</span>


<h1 id="the-digital-realm">The digital realm</h1>

<p>It all starts within the digital device, which can be any computer or computer-like gadget (PC, smartphone, Bluetooth receiver, etc.). Most devices read or receive audio data in <em>digitally compressed</em> form. Popular digital compression algorithms include <a href="https://en.wikipedia.org/wiki/MP3">MP3</a>, <a href="https://en.wikipedia.org/wiki/Advanced_Audio_Coding">AAC</a> and <a href="https://en.wikipedia.org/wiki/FLAC">FLAC</a>.</p>

<p><a href="https://en.wikipedia.org/wiki/Data_compression">Digital compression</a> <strong class="inlineFootnoteDecoration"> [note] </strong><span class="inlineFootnote-note inlineFootnoteUnprocessed">Not to be confused with <em><a href="https://en.wikipedia.org/wiki/Dynamic_range_compression">dynamic range compression</a></em>, which is completely unrelated.</span><strong class="inlineFootnoteDecoration"> [end note] </strong> is a complicated subject, which I won’t dig into further in this post. In any case, the data first goes through a <em>decoder</em> which converts the compressed signal into uncompressed form, which looks like this:</p>

<span class="figure" data-intrinsic-placeholder="unprocessed">
	<img src="https://factualaudio.com/plots/sine-wave-1khz-digital.png" alt="Digitally sampled 1kHz sine waveform" data-svg-alternative="https://factualaudio.com/plots/sine-wave-1khz-digital.svg">
</span>


<p>This plot shows that, in the digital realm, audio is not represented by a continuous, smoothly changing signal — instead, all we have are regularly-spaced “snapshots” that indicate what the signal amplitude is at some point in time. This is called a <em><a href="https://en.wikipedia.org/wiki/Discrete-time_signal">discrete signal</a></em>, and the “snapshots” are called <em>samples</em>. In this example, we have 44100 samples every second, or more formally, the <em>sample rate</em> is 44.1 kHz. Such a sample rate is standard for music — other types of content, such as movies or games, use a slightly higher rate, 48 kHz, for mostly historical reasons.</p>

<p>Because memory is not infinite, each sample value has a finite precision. In practice, each sample is typically converted to a signed integer with a precision, or <em><a href="https://en.wikipedia.org/wiki/Audio_bit_depth">bit depth</a></em>, of 16 bits. This process is called <em><a href="https://en.wikipedia.org/wiki/Quantization_%28signal_processing%29">quantization</a></em>. A 16-bit signed integer can take a value from -32768 to +32767. Samples outside of this range cannot be represented, and will be clamped to the nearest possible value; this is called <em>digital <a href="https://en.wikipedia.org/wiki/Clipping_%28signal_processing%29">clipping</a></em>, and is best avoided as it sounds quite bad. A signal that peaks at the highest possible amplitude without clipping is called a <em>full-range</em> or <em>full-scale</em> signal<strong class="inlineFootnoteDecoration"> [ref] </strong><span class="inlineFootnote-ref inlineFootnoteUnprocessed"><a href="https://webstore.iec.ch/publication/5664">IEC 61606–1:2009</a>, <em>Digital audio parts — Basic measurement methods of audio characteristics — General</em>, §3.1.10</span><strong class="inlineFootnoteDecoration"> [end ref] </strong>.</p>

<p>Finally, the signal is physically represented simply by transmitting the value of each point, or <em>sample</em>, one after the other. For example, the above signal is transmitted as 4653, 9211, 13583, etc. in the form of binary numbers. This way of transmitting the signal is called <em><a href="https://en.wikipedia.org/wiki/Pulse-code_modulation">pulse-code modulation</a></em>.</p>

<p>This section just skirted the surface of how digital audio works. The details of how sampled signals behave in practice are often counter-intuitive; as a result, misrepresentation of digital audio phenomena is quite commonplace in the audiophile community, leading to confusion and misguided advice. Digital audio expert <a href="https://en.wikipedia.org/wiki/Chris_Montgomery">Chris Montgomery</a> produced a <a href="https://xiph.org/video/">series of videos</a> that explains these complex phenomena with very clear and straightforward examples — it is a highly recommended resource if you wish to learn more about the digital realm.</p>

<h1 id="the-analog-realm">The analog realm</h1>

<p>Loudspeakers and headphones cannot receive a digital signal; it has to be converted to an <em>analog</em> signal first. This conversion is done in an electronic circuit appropriately named the <em><a href="https://en.wikipedia.org/wiki/Digital-to-analog_converter">digital-to-analog converter</a></em>, or DAC. This is where computer engineering ends and electrical engineering begins. The main task of the DAC is to take each sample value and convert it to some electrical <em><a href="https://en.wikipedia.org/wiki/Voltage">voltage</a></em> on its output pins. The resulting signal looks like the following:</p>

<span class="figure" data-intrinsic-placeholder="unprocessed">
	<img src="https://factualaudio.com/plots/sine-wave-1khz-analog.png" alt="1kHz sine wave with voltage scale" data-svg-alternative="https://factualaudio.com/plots/sine-wave-1khz-analog.svg">
</span>


<p class="caution"><strong class="caution-label">Caution: </strong>In the plot above, the unit used for the vertical scale is the <em><a href="https://en.wikipedia.org/wiki/Volt">volt</a></em>. In other words, the amplitude of the audio signal in the analog domain is defined by its <em>voltage</em>. It is <em>not</em> defined by <a href="https://en.wikipedia.org/wiki/Electric_current">current</a> nor <a href="https://en.wikipedia.org/wiki/Electric_power">power</a>. Even when the signal is used as the input of a loudspeaker, it is still voltage that determines the sound that comes out; power dissipation is a <em>consequence</em>, not a <em>cause</em>, of the audio signal flowing through the loudspeaker. As Pat Brown <a href="http://www.prosoundtraining.com/site/author/pat-brown/meaningful-metrics-the-use-and-abuse-of-loudspeaker-power-ratings/">elegantly puts it</a>: &ldquo;power is <em>drawn</em>, not applied&rdquo;. <strong class="inlineFootnoteDecoration"> [note] </strong><span class="inlineFootnote-note inlineFootnoteUnprocessed">Another way to state this is to say that properly engineered analog audio devices act as <em><a href="https://en.wikipedia.org/wiki/Voltage_source">voltage sources</a></em> (or sinks), which are connected to each other by way of <em><a href="https://en.wikipedia.org/wiki/Impedance_bridging">impedance bridging</a></em>.</span><strong class="inlineFootnoteDecoration"> [end note] </strong></p>


<p>The DAC took our discrete signal and converted it into a continuous electrical signal, whose voltage is (hopefully) <em>proportional</em> to the digital sample value. The central (mean) value of the signal, called the <em><a href="https://en.wikipedia.org/wiki/DC_bias">DC offset</a></em>, is zero volts; the signal swings around that central value, <em><a href="https://en.wikipedia.org/wiki/Alternating_current">alternating</a></em> between positive and negative voltage. In this example, our full-scale digital stream was converted to an analog signal that swings between -1.41 V and +1.41 V. Depending on the specific model of DAC used, its volume control setting (if any) and the signals involved, these numbers can vary — typical peak amplitude can go as low as 0.5 V <strong class="inlineFootnoteDecoration"> [ref] </strong><span class="inlineFootnote-ref inlineFootnoteUnprocessed">Wikipedia, <em><a href="https://en.wikipedia.org/wiki/Line_level#Nominal_levels">Nominal levels</a></em>, peak amplitude for consumer audio</span><strong class="inlineFootnoteDecoration"> [end ref] </strong> or as high as 2.8 V <strong class="inlineFootnoteDecoration"> [ref] </strong><span class="inlineFootnote-ref inlineFootnoteUnprocessed"><a href="https://webstore.iec.ch/publication/6142">IEC 61938:2013</a>, <em>Guide to the recommended characteristics of analogue interfaces to achieve interoperability</em>, §8.2.1</span><strong class="inlineFootnoteDecoration"> [end ref] </strong>.</p>

<p>The amount of <em>current</em> or <em>power</em> transferred from the source of an analog signal (e.g. a DAC) to the equipment plugged in at the other end of the cable (the <em><a href="https://en.wikipedia.org/wiki/Electrical_load">load</a></em>, e.g. a loudspeaker) is determined by the <em><a href="https://en.wikipedia.org/wiki/Electrical_impedance">impedance</a></em> of the load, also known as the <em><a href="https://en.wikipedia.org/wiki/Input_impedance">input impedance</a></em>. According to <a href="https://en.wikipedia.org/wiki/Ohm's_law">Ohm’s law</a>, the lower the impedance, the more current, and therefore power, will be required to sustain a given voltage.</p>

<p>DACs, as well as most other types of analog audio equipment (such as filters or mixers), are not designed to provide significant amounts of power. Instead, they are meant to be connected to a high-impedance load, normally 20 kΩ or higher <strong class="inlineFootnoteDecoration"> [ref] </strong><span class="inlineFootnote-ref inlineFootnoteUnprocessed"><a href="https://webstore.iec.ch/publication/6142">IEC 61938:2013</a>, <em>Guide to the recommended characteristics of analogue interfaces to achieve interoperability</em>, §8.2.1</span><strong class="inlineFootnoteDecoration"> [end ref] </strong>. This means that the load is acting much like a <a href="https://en.wikipedia.org/wiki/Voltmeter">voltmeter</a> or oscilloscope — it is “peeking” at the input voltage without drawing significant power from it. Such a signal that carries some voltage but very little power is called a <em><a href="https://en.wikipedia.org/wiki/Line_level">line-level</a></em> signal.</p>

<p>On the other hand, loudspeakers (and headphones to a lesser extent) are low-impedance devices — often between 4 Ω and 8 Ω in the case of speakers. This is because they operate under a relatively low voltage, but require a lot of power. For example, most speakers will happily produce comfortably loud sound with as little as 6 V, but might consume as much as 9 <a href="https://en.wikipedia.org/wiki/Watt">watts</a> while doing so <strong class="inlineFootnoteDecoration"> [note] </strong><span class="inlineFootnote-note inlineFootnoteUnprocessed">From the numbers given a keen eye will <a href="http://www.sengpielaudio.com/calculator-ohm.htm">deduce</a> that this example speaker has an impedance of 4 Ω. One thing to note is that loudspeaker impedance is highly dependent on the frequency of the signal, making the use of one number an oversimplification. The impedance that manufacturers advertise, called the <em>rated impedance</em>, is 1.25 times the <em>minimum</em> impedance of the speaker across its rated frequency range. (see <a href="https://webstore.iec.ch/publication/1223">IEC 60268–5:2003</a>, <em>Loudspeakers</em>, §16.1)</span><strong class="inlineFootnoteDecoration"> [end note] </strong>. Line-level equipment is not designed to provide such a large amount of power.</p>

<p>This problem is solved by using a <em><a href="https://en.wikipedia.org/wiki/Audio_power_amplifier">power amplifier</a></em>. This is a component that conveniently provides a high-impedance input for connecting line-level equipment, while exposing an output that is capable of providing large amounts of power, such as 10W or more, to a low-impedance load. <strong class="inlineFootnoteDecoration"> [note] </strong><span class="inlineFootnote-note inlineFootnoteUnprocessed">In practice, most amplifiers are also capable of increasing the voltage (amplitude) of the signal; this is called the <a href="https://en.wikipedia.org/wiki/Gain_%28electronics%29">gain</a> of the amplifier. This is because most loudspeakers require voltages that are somewhat higher than line level in order to play loud enough. Still, the primary goal of a power amplifier is to provide power, not to increase voltage.</span><strong class="inlineFootnoteDecoration"> [end note] </strong> Such outputs provide so-called <em>speaker-level signals</em>.</p>

<p>In some home audio systems, the DAC and the amplifier are integrated into one single device, which is called an <em>integrated amplifier</em> or more commonly an <em><a href="https://en.wikipedia.org/wiki/AV_receiver">AV receiver</a></em> (AVR).</p>

<h1 id="the-acoustic-realm">The acoustic realm</h1>

<p>Finally, in order to reach your ears, the analog signal must be converted to an <em>acoustic</em> signal, that is, actual <a href="https://en.wikipedia.org/wiki/Sound">sound waves</a>. This is accomplished using a device called an <em>electroacoustic <a href="https://en.wikipedia.org/wiki/Transducer">transducer</a></em>, or <em>driver</em>. The output of a driver when excited with our example signal, as measured at some point in front of it, might look like the following:</p>

<span class="figure" data-intrinsic-placeholder="unprocessed">
	<img src="https://factualaudio.com/plots/sine-wave-1khz-acoustic.png" alt="1kHz sine wave with pressure scale" data-svg-alternative="https://factualaudio.com/plots/sine-wave-1khz-acoustic.svg">
</span>


<p>Note the change of vertical scale. We’re not dealing with voltage anymore — amplitude takes the form of <em><a href="https://en.wikipedia.org/wiki/Sound_pressure">sound pressure</a></em> instead. Indeed, sound is a physical phenomenon in which transient changes in pressure (<em>compression</em>, <em>rarefaction</em>) produced by the vibration of a <em>sound source</em> propagate through the space around it. In other words, it is a <em><a href="https://en.wikipedia.org/wiki/Longitudinal_wave">longitudinal wave</a></em>. Sound pressure, expressed in <em><a href="https://en.wikipedia.org/wiki/Pascal_%28unit%29">Pascals</a></em> (Pa), quantifies the difference between normal atmospheric pressure and some local, dynamic change in pressure, at a given point in time and space. The human ear is equipped to detect these changes, which are then — finally! — perceived as sound by the human brain.</p>

<p>An ideal transducer will produce sound pressure <em>proportional</em> to the voltage applied to it, like in the above waveform. However, it is difficult to design a driver that is capable of doing that across the entire range of audible frequencies. Consequently, a number of transducer types are available, which are commonly referred to as <em><a href="https://en.wikipedia.org/wiki/Subwoofer">subwoofers</a></em>, <em><a href="https://en.wikipedia.org/wiki/Woofer">woofers</a></em>, <em><a href="https://en.wikipedia.org/wiki/Mid-range_speaker">midranges</a></em> and <em><a href="https://en.wikipedia.org/wiki/Tweeter">tweeters</a></em>.</p>

<p>In order to reproduce the entire range of human hearing, several of these drivers — often two or three — are assembled inside a single “box”, called the <em>enclosure</em>. In most designs the drivers are mounted flush with one side of the box, which is called the <em>front baffle</em>. An electrical circuit called a <em><a href="https://en.wikipedia.org/wiki/Audio_crossover">crossover</a></em> splits the input signal into the frequency ranges appropriate for each driver. The resulting device is called a <em><a href="https://en.wikipedia.org/wiki/Loudspeaker">loudspeaker</a></em>.</p>

<p>What I’ve described here is called a <em>passive</em> loudspeaker, which is the most common type in consumer “Hi-Fi” systems. Sometimes the amplifier and speaker are integrated into the same device; this is called an <em>active</em> or <em><a href="https://en.wikipedia.org/wiki/Powered_speakers">powered</a></em> speaker. Examples include professional “studio monitor” speakers, which have line-level inputs. Other products, such as “Bluetooth speakers”, go one step further and throw in a DAC as well for a completely integrated solution.</p>

<p><em><a href="https://en.wikipedia.org/wiki/Headphones">Headphones</a></em> are a special case and typically only have one driver per channel, which makes them simpler. Conceptually, a headphone is akin to a miniature loudspeaker. Because of their proximity to the ear, they don’t have to produce as much sound pressure; therefore they require much less power to operate (often less than 1 mW).</p>

<p>One notable aspect of the acoustic realm is that sound propagates in all three dimensions — the audio signal (sound pressure) is not the same at every point in space. In particular, speakers exhibit <em>radiation patterns</em> that vary with angle and frequency, and the sound they emit can bounce off surfaces (<em><a href="https://en.wikipedia.org/wiki/Reflection_%28physics%29#Sound_reflection">reflection</a></em>). This in turn means that they interact with their environment (the listening room, or, in the case of headphones, the listener’s head) in ways that are complex and difficult to predict but nonetheless have an enormous impact on how the radiated sound will be perceived by a human listener. This makes choosing and configuring a speaker system quite the challenge. Hopefully, future posts on this blog will provide some pointers.</p>

</div>

        <footer class="post-footer clearfix">
    

    <div class="share">
        
            <a class="icon-twitter" href="https://twitter.com/share?text=From%20bytes%20to%20your%20eardrum&amp;url=https%3a%2f%2ffactualaudio.com%2fpost%2flife%2f"
                onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;">
                <i class="fa fa-twitter"></i>
                <span class="hidden">Twitter</span>
            </a>
        

        
            <a class="icon-facebook" href="https://www.facebook.com/sharer/sharer.php?u=https%3a%2f%2ffactualaudio.com%2fpost%2flife%2f"
                onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;">
                <i class="fa fa-facebook"></i>
                <span class="hidden">Facebook</span>
            </a>
        

        
        
    </div>
</footer>

        
<div class="comments">
	<div id="disqus_thread"></div>
</div>

    </article>
</div>

            </div>
        </div>

        <footer class="footer">
            <div class="container">
                <div class="site-title-wrapper">
                    <h1 class="site-title">
                        <a title="Factual Audio" href="https://factualaudio.com/">Factual Audio</a>
                    </h1>
                    <a class="button-square button-jump-top js-jump-top" href="#">
                        <i class="fa fa-angle-up"></i>
                    </a>
                </div>

		<p class="footer-about">
	<a href="https://factualaudio.com/page/about/">About Factual Audio</a>
</p>
<p class="footer-copyright">
	This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.
</p>


                <p class="footer-copyright">
                    <span>&copy; 2018 <a href="https://factualaudio.com/page/about/" rel="author">Etienne Dechamps</a> / Powered by <a href="https://gohugo.io/">Hugo</a></span>
                </p>
                <p class="footer-copyright">
                    <span><a href="https://github.com/roryg/ghostwriter">Ghostwriter theme</a> By <a href="http://jollygoodthemes.com">JollyGoodThemes</a></span>
                    <span>/ <a href="https://github.com/jbub/ghostwriter">Ported</a> to Hugo By <a href="https://github.com/jbub">jbub</a></span>
                </p>
            </div>
        </footer>
    </body>
</html>

